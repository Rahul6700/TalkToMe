{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdIt3NEnE3K5cNYZFtWRNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahul6700/TalkToMe/blob/main/testVR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install resemblyzer numpy scipy librosa soundfile torch audioread"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mCGzR2Oi-p08",
        "outputId": "345f92dd-d7fc-4b6c-ef70-1992bd8d701c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting resemblyzer\n",
            "  Downloading Resemblyzer-0.1.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: audioread in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Collecting webrtcvad>=2.0.10 (from resemblyzer)\n",
            "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing (from resemblyzer)\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Downloading Resemblyzer-0.1.4-py3-none-any.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m862.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: webrtcvad, typing\n",
            "  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp311-cp311-linux_x86_64.whl size=73497 sha256=e1b4b4da9bbb274739b64949e97f08e7816e1bc46486a94e74ca7f3ce12b497b\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/65/3f/292d0b656be33d1c801831201c74b5f68f41a2ae465ff2ee2f\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26303 sha256=968600543d6943747fd5afd81a5ada7eb5d5cde712b36a3193d4b5aac1190c09\n",
            "  Stored in directory: /root/.cache/pip/wheels/9d/67/2f/53e3ef32ec48d11d7d60245255e2d71e908201d20c880c08ee\n",
            "Successfully built webrtcvad typing\n",
            "Installing collected packages: webrtcvad, typing, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, resemblyzer\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 resemblyzer-0.1.4 typing-3.7.4.3 webrtcvad-2.0.10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              },
              "id": "490b2657f0ab4427ba5d7433fdf0f6b0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXlErjPJUIAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18cff6df-26cc-4d02-890b-20f27b5ea2e3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.03 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-269c95b8387f>:22: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.02 seconds.\n",
            "Loaded the voice encoder model on cpu in 0.01 seconds.\n",
            "Top 5 Matches:\n",
            "Speaker: RS_m_4, Similarity Score: 0.8081\n",
            "Speaker: KP_M_3, Similarity Score: 0.7765\n",
            "Speaker: RS_m_1, Similarity Score: 0.7408\n",
            "Speaker: RM_M_7, Similarity Score: 0.7307\n",
            "Speaker: RS_m_2, Similarity Score: 0.7194\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "from resemblyzer import preprocess_wav, VoiceEncoder\n",
        "from scipy.spatial.distance import cosine\n",
        "import zipfile\n",
        "\n",
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio file with noise reduction and normalization\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to audio file\n",
        "        target_sr (int): Target sampling rate\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Preprocessed audio signal\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio file with librosa (supports multiple formats)\n",
        "        audio, orig_sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # Resample if needed\n",
        "        if orig_sr != target_sr:\n",
        "            audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
        "\n",
        "        # Noise reduction using spectral gating\n",
        "        def noise_reduce(y):\n",
        "            # Compute the spectrogram\n",
        "            stft = librosa.stft(y)\n",
        "\n",
        "            # Estimate noise\n",
        "            noise_thresh = np.median(np.abs(stft), axis=1)\n",
        "\n",
        "            # Create a mask to reduce noise\n",
        "            mask = np.abs(stft) > noise_thresh[:, np.newaxis]\n",
        "\n",
        "            # Apply mask\n",
        "            cleaned_stft = stft * mask\n",
        "\n",
        "            # Convert back to time domain\n",
        "            return librosa.istft(cleaned_stft)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        audio = noise_reduce(audio)\n",
        "\n",
        "        # Normalize audio (RMS)\n",
        "        audio = audio / np.sqrt(np.mean(audio**2))\n",
        "\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_voice_embedding(audio):\n",
        "    \"\"\"\n",
        "    Extract voice embedding from preprocessed audio\n",
        "\n",
        "    Args:\n",
        "        audio (numpy.ndarray): Preprocessed audio signal\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Voice embedding vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create voice encoder\n",
        "        encoder = VoiceEncoder()\n",
        "\n",
        "        # Generate embedding\n",
        "        embedding = encoder.embed_utterance(audio)\n",
        "\n",
        "        return embedding\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def compare_voices(input_embedding, reference_embeddings, top_n=5):\n",
        "    \"\"\"\n",
        "    Compare input voice embedding with reference embeddings\n",
        "\n",
        "    Args:\n",
        "        input_embedding (numpy.ndarray): Embedding of input voice\n",
        "        reference_embeddings (dict): Dictionary of reference voice embeddings\n",
        "        top_n (int): Number of top matches to return\n",
        "\n",
        "    Returns:\n",
        "        list: Top N matches with similarity scores\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "\n",
        "    for name, ref_embedding in reference_embeddings.items():\n",
        "        # Calculate cosine similarity (lower score means more similar)\n",
        "        similarity_score = 1 - cosine(input_embedding, ref_embedding)\n",
        "        similarities.append((name, similarity_score))\n",
        "\n",
        "    # Sort similarities in descending order\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def process_speaker_recognition(input_file, reference_folder):\n",
        "    \"\"\"\n",
        "    Perform comprehensive speaker recognition\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to input voice file\n",
        "        reference_folder (str): Path to folder with reference voice files\n",
        "\n",
        "    Returns:\n",
        "        list: Top matches with similarity scores\n",
        "    \"\"\"\n",
        "    # Preprocess input voice\n",
        "    input_audio = load_and_preprocess_audio(input_file)\n",
        "\n",
        "    if input_audio is None:\n",
        "        return [(\"Error\", \"Could not process input voice file\")]\n",
        "\n",
        "    # Extract embedding for input voice\n",
        "    input_embedding = extract_voice_embedding(input_audio)\n",
        "\n",
        "    if input_embedding is None:\n",
        "        return [(\"Error\", \"Could not generate input voice embedding\")]\n",
        "\n",
        "    # Extract embeddings for all reference voices\n",
        "    reference_embeddings = {}\n",
        "    for filename in os.listdir(reference_folder):\n",
        "        # Support multiple audio formats\n",
        "        if filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):\n",
        "            filepath = os.path.join(reference_folder, filename)\n",
        "\n",
        "            # Preprocess reference audio\n",
        "            ref_audio = load_and_preprocess_audio(filepath)\n",
        "\n",
        "            if ref_audio is not None:\n",
        "                # Extract embedding\n",
        "                embedding = extract_voice_embedding(ref_audio)\n",
        "\n",
        "                if embedding is not None:\n",
        "                    # Use filename (without extension) as the speaker name\n",
        "                    speaker_name = os.path.splitext(filename)[0]\n",
        "                    reference_embeddings[speaker_name] = embedding\n",
        "\n",
        "    # Compare embeddings and get top matches\n",
        "    top_matches = compare_voices(input_embedding, reference_embeddings)\n",
        "\n",
        "    return top_matches\n",
        "\n",
        "# Unzip the folder\n",
        "def unzip_folder(zip_path, extract_to='.'):\n",
        "    \"\"\"\n",
        "    Unzip a folder\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): Path to zip file\n",
        "        extract_to (str): Destination folder\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage\n",
        "# First, unzip the folder\n",
        "unzip_folder('present_maam.zip')\n",
        "\n",
        "# Then run speaker recognition\n",
        "input_voice_file = 'rahultest5.m4a'  # Replace with your input voice file\n",
        "reference_voices_folder = 'present_maam'  # Folder extracted from zip\n",
        "\n",
        "# Perform speaker recognition\n",
        "results = process_speaker_recognition(input_voice_file, reference_voices_folder)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 Matches:\")\n",
        "for name, score in results:\n",
        "    print(f\"Speaker: {name}, Similarity Score: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using speechbrain (taking a good amount of time to run tho)"
      ],
      "metadata": {
        "id": "YSk2lXcBNsFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechbrain torchaudio librosa numpy scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OZ7ItBuKN2T6",
        "outputId": "739c0f05-4e18-48a3-9314-47b4ed077890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Collecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (24.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.67.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.29.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->speechbrain)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->speechbrain) (1.3.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.13.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (6.0.2)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (3.0.2)\n",
            "Downloading speechbrain-1.0.2-py3-none-any.whl (824 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.7/117.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ruamel.yaml, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, hyperpyyaml, speechbrain\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed hyperpyyaml-1.2.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 speechbrain-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from scipy.spatial.distance import cosine\n",
        "import zipfile\n",
        "\n",
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio file with noise reduction and normalization\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to audio file\n",
        "        target_sr (int): Target sampling rate\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Preprocessed audio signal\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio file with librosa (supports multiple formats)\n",
        "        audio, orig_sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # Resample if needed\n",
        "        if orig_sr != target_sr:\n",
        "            audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
        "\n",
        "        # Noise reduction using spectral gating\n",
        "        def noise_reduce(y):\n",
        "            # Compute the spectrogram\n",
        "            stft = librosa.stft(y)\n",
        "\n",
        "            # Estimate noise\n",
        "            noise_thresh = np.median(np.abs(stft), axis=1)\n",
        "\n",
        "            # Create a mask to reduce noise\n",
        "            mask = np.abs(stft) > noise_thresh[:, np.newaxis]\n",
        "\n",
        "            # Apply mask\n",
        "            cleaned_stft = stft * mask\n",
        "\n",
        "            # Convert back to time domain\n",
        "            return librosa.istft(cleaned_stft)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        audio = noise_reduce(audio)\n",
        "\n",
        "        # Normalize audio (RMS)\n",
        "        audio = audio / np.sqrt(np.mean(audio**2))\n",
        "\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_voice_embedding(audio):\n",
        "    \"\"\"\n",
        "    Extract voice embedding from preprocessed audio\n",
        "\n",
        "    Args:\n",
        "        audio (numpy.ndarray): Preprocessed audio signal\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Voice embedding vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Import SpeechBrain speaker recognition\n",
        "        from speechbrain.pretrained import SpeakerRecognition\n",
        "\n",
        "        # Initialize model\n",
        "        model = SpeakerRecognition.from_hparams(\n",
        "            source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "            savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        "        )\n",
        "\n",
        "        # Convert numpy array to torch tensor\n",
        "        # Ensure the audio is in the right shape and type\n",
        "        audio_tensor = torch.tensor(audio).float().unsqueeze(0)\n",
        "\n",
        "        # Ensure the tensor is the right length (3 seconds at 16kHz)\n",
        "        target_length = 3 * 16000\n",
        "        if audio_tensor.shape[1] > target_length:\n",
        "            audio_tensor = audio_tensor[:, :target_length]\n",
        "        elif audio_tensor.shape[1] < target_length:\n",
        "            padding = torch.zeros(1, target_length - audio_tensor.shape[1])\n",
        "            audio_tensor = torch.cat([audio_tensor, padding], dim=1)\n",
        "\n",
        "        # Extract embedding\n",
        "        embedding = model.encode_batch(audio_tensor)\n",
        "\n",
        "        return embedding.squeeze().numpy()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def compare_voices(input_embedding, reference_embeddings, top_n=5):\n",
        "    \"\"\"\n",
        "    Compare input voice embedding with reference embeddings\n",
        "\n",
        "    Args:\n",
        "        input_embedding (numpy.ndarray): Embedding of input voice\n",
        "        reference_embeddings (dict): Dictionary of reference voice embeddings\n",
        "        top_n (int): Number of top matches to return\n",
        "\n",
        "    Returns:\n",
        "        list: Top N matches with similarity scores\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "\n",
        "    for name, ref_embedding in reference_embeddings.items():\n",
        "        # Calculate cosine similarity (lower score means more similar)\n",
        "        similarity_score = 1 - cosine(input_embedding, ref_embedding)\n",
        "        similarities.append((name, similarity_score))\n",
        "\n",
        "    # Sort similarities in descending order\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def process_speaker_recognition(input_file, reference_folder):\n",
        "    \"\"\"\n",
        "    Perform comprehensive speaker recognition\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to input voice file\n",
        "        reference_folder (str): Path to folder with reference voice files\n",
        "\n",
        "    Returns:\n",
        "        list: Top matches with similarity scores\n",
        "    \"\"\"\n",
        "    # Preprocess input voice\n",
        "    input_audio = load_and_preprocess_audio(input_file)\n",
        "\n",
        "    if input_audio is None:\n",
        "        return [(\"Error\", \"Could not process input voice file\")]\n",
        "\n",
        "    # Extract embedding for input voice\n",
        "    input_embedding = extract_voice_embedding(input_audio)\n",
        "\n",
        "    if input_embedding is None:\n",
        "        return [(\"Error\", \"Could not generate input voice embedding\")]\n",
        "\n",
        "    # Extract embeddings for all reference voices\n",
        "    reference_embeddings = {}\n",
        "    for filename in os.listdir(reference_folder):\n",
        "        # Support multiple audio formats\n",
        "        if filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):\n",
        "            filepath = os.path.join(reference_folder, filename)\n",
        "\n",
        "            # Preprocess reference audio\n",
        "            ref_audio = load_and_preprocess_audio(filepath)\n",
        "\n",
        "            if ref_audio is not None:\n",
        "                # Extract embedding\n",
        "                embedding = extract_voice_embedding(ref_audio)\n",
        "\n",
        "                if embedding is not None:\n",
        "                    # Use filename (without extension) as the speaker name\n",
        "                    speaker_name = os.path.splitext(filename)[0]\n",
        "                    reference_embeddings[speaker_name] = embedding\n",
        "\n",
        "    # Compare embeddings and get top matches\n",
        "    top_matches = compare_voices(input_embedding, reference_embeddings)\n",
        "\n",
        "    return top_matches\n",
        "\n",
        "# Unzip the folder\n",
        "def unzip_folder(zip_path, extract_to='.'):\n",
        "    \"\"\"\n",
        "    Unzip a folder\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): Path to zip file\n",
        "        extract_to (str): Destination folder\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage\n",
        "# First, unzip the folder\n",
        "unzip_folder('present_maam.zip')\n",
        "\n",
        "# Then run speaker recognition\n",
        "input_voice_file = 'rahultest1.m4a'  # Replace with your input voice file\n",
        "reference_voices_folder = 'present_maam'  # Folder extracted from zip\n",
        "\n",
        "# Perform speaker recognition\n",
        "results = process_speaker_recognition(input_voice_file, reference_voices_folder)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 Matches:\")\n",
        "for name, score in results:\n",
        "    print(f\"Speaker: {name}, Similarity Score: {score:.4f}\")"
      ],
      "metadata": {
        "id": "BkDp4cX92fDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "c147335c-710f-4dc6-8830-c9a69b94ac9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-23-3579387b5dec>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Matches:\n",
            "Speaker: RS_m_5, Similarity Score: 0.6402\n",
            "Speaker: RM_M_3, Similarity Score: 0.5164\n",
            "Speaker: RS_m_4, Similarity Score: 0.3876\n",
            "Speaker: KP_M_6, Similarity Score: 0.3652\n",
            "Speaker: RM_M_9, Similarity Score: 0.3405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using MFCC's manually (with no model)\n"
      ],
      "metadata": {
        "id": "-F5oAKqGRT0N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy librosa soundfile torch torchaudio scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Xl0OBgiGRXrK",
        "outputId": "1ce14011-8074-4cd7-c723-e3c47cc12d22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from lazy_loader>=0.1->librosa) (24.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from scipy.spatial.distance import cosine\n",
        "import zipfile\n",
        "\n",
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio file with noise reduction and normalization\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to audio file\n",
        "        target_sr (int): Target sampling rate\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Preprocessed audio signal\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio file with librosa (supports multiple formats)\n",
        "        audio, orig_sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # Resample if needed\n",
        "        if orig_sr != target_sr:\n",
        "            audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
        "\n",
        "        # Noise reduction using spectral gating\n",
        "        def noise_reduce(y):\n",
        "            # Compute the spectrogram\n",
        "            stft = librosa.stft(y)\n",
        "\n",
        "            # Estimate noise\n",
        "            noise_thresh = np.median(np.abs(stft), axis=1)\n",
        "\n",
        "            # Create a mask to reduce noise\n",
        "            mask = np.abs(stft) > noise_thresh[:, np.newaxis]\n",
        "\n",
        "            # Apply mask\n",
        "            cleaned_stft = stft * mask\n",
        "\n",
        "            # Convert back to time domain\n",
        "            return librosa.istft(cleaned_stft)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        audio = noise_reduce(audio)\n",
        "\n",
        "        # Normalize audio (RMS)\n",
        "        audio = audio / np.sqrt(np.mean(audio**2))\n",
        "\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_voice_embedding(audio):\n",
        "    \"\"\"\n",
        "    Extract voice embedding from preprocessed audio using MFCC features\n",
        "\n",
        "    Args:\n",
        "        audio (numpy.ndarray): Preprocessed audio signal\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Voice embedding vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure audio is the right length\n",
        "        target_length = 3 * 16000  # 3 seconds at 16kHz\n",
        "        if len(audio) > target_length:\n",
        "            audio = audio[:target_length]\n",
        "        elif len(audio) < target_length:\n",
        "            audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
        "\n",
        "        # Extract MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13)\n",
        "\n",
        "        # Compute the mean and standard deviation of MFCCs\n",
        "        mfcc_mean = np.mean(mfccs, axis=1)\n",
        "        mfcc_std = np.std(mfccs, axis=1)\n",
        "\n",
        "        # Combine mean and std into a single embedding vector\n",
        "        embedding = np.concatenate([mfcc_mean, mfcc_std])\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def compare_voices(input_embedding, reference_embeddings, top_n=5):\n",
        "    \"\"\"\n",
        "    Compare input voice embedding with reference embeddings\n",
        "\n",
        "    Args:\n",
        "        input_embedding (numpy.ndarray): Embedding of input voice\n",
        "        reference_embeddings (dict): Dictionary of reference voice embeddings\n",
        "        top_n (int): Number of top matches to return\n",
        "\n",
        "    Returns:\n",
        "        list: Top N matches with similarity scores\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "\n",
        "    for name, ref_embedding in reference_embeddings.items():\n",
        "        # Calculate cosine similarity (lower score means more similar)\n",
        "        similarity_score = 1 - cosine(input_embedding, ref_embedding)\n",
        "        similarities.append((name, similarity_score))\n",
        "\n",
        "    # Sort similarities in descending order\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def process_speaker_recognition(input_file, reference_folder):\n",
        "    \"\"\"\n",
        "    Perform comprehensive speaker recognition\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to input voice file\n",
        "        reference_folder (str): Path to folder with reference voice files\n",
        "\n",
        "    Returns:\n",
        "        list: Top matches with similarity scores\n",
        "    \"\"\"\n",
        "    # Preprocess input voice\n",
        "    input_audio = load_and_preprocess_audio(input_file)\n",
        "\n",
        "    if input_audio is None:\n",
        "        return [(\"Error\", \"Could not process input voice file\")]\n",
        "\n",
        "    # Extract embedding for input voice\n",
        "    input_embedding = extract_voice_embedding(input_audio)\n",
        "\n",
        "    if input_embedding is None:\n",
        "        return [(\"Error\", \"Could not generate input voice embedding\")]\n",
        "\n",
        "    # Extract embeddings for all reference voices\n",
        "    reference_embeddings = {}\n",
        "    for filename in os.listdir(reference_folder):\n",
        "        # Support multiple audio formats\n",
        "        if filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):\n",
        "            filepath = os.path.join(reference_folder, filename)\n",
        "\n",
        "            # Preprocess reference audio\n",
        "            ref_audio = load_and_preprocess_audio(filepath)\n",
        "\n",
        "            if ref_audio is not None:\n",
        "                # Extract embedding\n",
        "                embedding = extract_voice_embedding(ref_audio)\n",
        "\n",
        "                if embedding is not None:\n",
        "                    # Use filename (without extension) as the speaker name\n",
        "                    speaker_name = os.path.splitext(filename)[0]\n",
        "                    reference_embeddings[speaker_name] = embedding\n",
        "\n",
        "    # Compare embeddings and get top matches\n",
        "    top_matches = compare_voices(input_embedding, reference_embeddings)\n",
        "\n",
        "    return top_matches\n",
        "\n",
        "# Unzip the folder\n",
        "def unzip_folder(zip_path, extract_to='.'):\n",
        "    \"\"\"\n",
        "    Unzip a folder\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): Path to zip file\n",
        "        extract_to (str): Destination folder\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage\n",
        "# First, unzip the folder\n",
        "unzip_folder('present_maam.zip')\n",
        "\n",
        "# Then run speaker recognition\n",
        "input_voice_file = 'rahultest5.m4a'  # Replace with your input voice file\n",
        "reference_voices_folder = 'present_maam'  # Folder extracted from zip\n",
        "\n",
        "# Perform speaker recognition\n",
        "results = process_speaker_recognition(input_voice_file, reference_voices_folder)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 Matches:\")\n",
        "for name, score in results:\n",
        "    print(f\"Speaker: {name}, Similarity Score: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MNuYlsR3Re3l",
        "outputId": "743996bb-ec86-4c16-c916-aba21ff64b86",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-3-d36ed90b59a6>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d36ed90b59a6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;31m# Perform speaker recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_speaker_recognition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_voice_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_voices_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;31m# Print results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d36ed90b59a6>\u001b[0m in \u001b[0;36mprocess_speaker_recognition\u001b[0;34m(input_file, reference_folder)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mref_audio\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0;31m# Extract embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_voice_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-d36ed90b59a6>\u001b[0m in \u001b[0;36mextract_voice_embedding\u001b[0;34m(audio)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mframe_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mlpcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_lpcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_lpcc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mlpcc_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlpcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-f19630728656>\u001b[0m in \u001b[0;36mextract_lpcc\u001b[0;34m(audio, sr, n_lpcc)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Step 1: Compute LPC coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mlpc_coeffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_lpcc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# Step 2: Convert LPC to LPCC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mlpc\u001b[0;34m(y, order, axis)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0mden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreflect_coeff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;31m# Call the helper, and swap the results back to the target axis position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/librosa/util/utils.py\u001b[0m in \u001b[0;36mtiny\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtiny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0m_finfo_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finfo_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# most common path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now trying MFCC's + LPCC's"
      ],
      "metadata": {
        "id": "OMsmtLPn4IvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from scipy.spatial.distance import cosine\n",
        "import zipfile\n",
        "\n",
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio file with noise reduction and normalization\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to audio file\n",
        "        target_sr (int): Target sampling rate\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Preprocessed audio signal\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio file with librosa (supports multiple formats)\n",
        "        audio, orig_sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # Resample if needed\n",
        "        if orig_sr != target_sr:\n",
        "            audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
        "\n",
        "        # Noise reduction using spectral gating\n",
        "        def noise_reduce(y):\n",
        "            # Compute the spectrogram\n",
        "            stft = librosa.stft(y)\n",
        "\n",
        "            # Estimate noise\n",
        "            noise_thresh = np.median(np.abs(stft), axis=1)\n",
        "\n",
        "            # Create a mask to reduce noise\n",
        "            mask = np.abs(stft) > noise_thresh[:, np.newaxis]\n",
        "\n",
        "            # Apply mask\n",
        "            cleaned_stft = stft * mask\n",
        "\n",
        "            # Convert back to time domain\n",
        "            return librosa.istft(cleaned_stft)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        audio = noise_reduce(audio)\n",
        "\n",
        "        # Normalize audio (RMS)\n",
        "        audio = audio / np.sqrt(np.mean(audio**2))\n",
        "\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_lpcc(audio, sr=16000, n_lpcc=13):\n",
        "    \"\"\"\n",
        "    Extract Linear Prediction Cepstral Coefficients (LPCC) features\n",
        "\n",
        "    Args:\n",
        "        audio (numpy.ndarray): Audio signal\n",
        "        sr (int): Sampling rate\n",
        "        n_lpcc (int): Number of LPCC coefficients to extract\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: LPCC features\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Apply pre-emphasis filter\n",
        "        preemphasis = 0.97\n",
        "        audio = np.append(audio[0], audio[1:] - preemphasis * audio[:-1])\n",
        "\n",
        "        # Step 1: Compute LPC coefficients\n",
        "        lpc_coeffs = librosa.lpc(audio, order=n_lpcc)\n",
        "\n",
        "        # Handle potential instability in LPC\n",
        "        if np.isnan(lpc_coeffs).any() or np.isinf(lpc_coeffs).any():\n",
        "            print(\"Warning: LPC coefficients contain NaN or Inf values\")\n",
        "            return np.random.normal(0, 0.1, n_lpcc)  # Return random coefficients\n",
        "\n",
        "        # Step 2: Convert LPC to LPCC\n",
        "        lpcc = np.zeros(n_lpcc)\n",
        "\n",
        "        # First LPCC coefficient\n",
        "        lpcc[0] = -np.log(lpc_coeffs[0]) if lpc_coeffs[0] > 0 else 0\n",
        "\n",
        "        # Rest of LPCC coefficients\n",
        "        for n in range(1, n_lpcc):\n",
        "            lpcc[n] = lpc_coeffs[n]\n",
        "\n",
        "            for k in range(1, n):\n",
        "                lpcc[n] += lpcc[k] * lpc_coeffs[n-k] * (n-k) / n\n",
        "\n",
        "            lpcc[n] = -lpcc[n]\n",
        "\n",
        "        return lpcc\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting LPCC: {e}\")\n",
        "        return np.random.normal(0, 0.1, n_lpcc)  # Return random coefficients\n",
        "\n",
        "def extract_voice_embedding(audio):\n",
        "    \"\"\"\n",
        "    Extract voice embedding from preprocessed audio using MFCC and LPCC features\n",
        "\n",
        "    Args:\n",
        "        audio (numpy.ndarray): Preprocessed audio signal\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Voice embedding vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure audio is the right length\n",
        "        target_length = 3 * 16000  # 3 seconds at 16kHz\n",
        "        if len(audio) > target_length:\n",
        "            audio = audio[:target_length]\n",
        "        elif len(audio) < target_length:\n",
        "            audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
        "\n",
        "        # Extract MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13)\n",
        "\n",
        "        # Compute the mean and standard deviation of MFCCs\n",
        "        mfcc_mean = np.mean(mfccs, axis=1)\n",
        "        mfcc_std = np.std(mfccs, axis=1)\n",
        "\n",
        "        # Extract LPCC features for several frames and compute statistics\n",
        "        frame_length = int(0.025 * 16000)  # 25ms\n",
        "        hop_length = int(0.010 * 16000)    # 10ms\n",
        "\n",
        "        lpcc_features = []\n",
        "        for i in range(0, len(audio) - frame_length, hop_length):\n",
        "            frame = audio[i:i + frame_length]\n",
        "            lpcc = extract_lpcc(frame, sr=16000, n_lpcc=13)\n",
        "            lpcc_features.append(lpcc)\n",
        "\n",
        "        lpcc_features = np.array(lpcc_features)\n",
        "\n",
        "        # Compute mean and standard deviation of LPCC features\n",
        "        lpcc_mean = np.mean(lpcc_features, axis=0)\n",
        "        lpcc_std = np.std(lpcc_features, axis=0)\n",
        "\n",
        "        # Combine MFCC and LPCC features into a single embedding vector\n",
        "        embedding = np.concatenate([mfcc_mean, mfcc_std, lpcc_mean, lpcc_std])\n",
        "\n",
        "        # Add small random noise to prevent perfect matches\n",
        "        np.random.seed(42)  # For reproducibility\n",
        "        embedding += np.random.normal(0, 1e-5, embedding.shape)\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def compare_voices(input_embedding, reference_embeddings, top_n=5):\n",
        "    \"\"\"\n",
        "    Compare input voice embedding with reference embeddings\n",
        "\n",
        "    Args:\n",
        "        input_embedding (numpy.ndarray): Embedding of input voice\n",
        "        reference_embeddings (dict): Dictionary of reference voice embeddings\n",
        "        top_n (int): Number of top matches to return\n",
        "\n",
        "    Returns:\n",
        "        list: Top N matches with similarity scores\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "\n",
        "    # Debug: check if input embedding has valid values\n",
        "    if np.all(np.isnan(input_embedding)) or np.all(input_embedding == 0):\n",
        "        print(\"Warning: Input embedding contains all NaN or zero values\")\n",
        "        return [(\"Error\", 0.0)]\n",
        "\n",
        "    for name, ref_embedding in reference_embeddings.items():\n",
        "        # Skip invalid embeddings\n",
        "        if np.all(np.isnan(ref_embedding)) or np.all(ref_embedding == 0):\n",
        "            print(f\"Warning: Reference embedding for {name} contains all NaN or zero values\")\n",
        "            continue\n",
        "\n",
        "        # 1. Cosine similarity (bounded between -1 and 1)\n",
        "        cosine_sim = 1 - cosine(input_embedding, ref_embedding)\n",
        "\n",
        "        # 2. Modified Euclidean similarity calculation\n",
        "        euclidean_dist = np.linalg.norm(input_embedding - ref_embedding)\n",
        "        # Use a more stable approach for Euclidean similarity\n",
        "        euclidean_sim = 1 / (1 + euclidean_dist)  # This will be between 0 and 1\n",
        "\n",
        "        # Combined score (weighted average)\n",
        "        similarity_score = 0.7 * cosine_sim + 0.3 * euclidean_sim\n",
        "\n",
        "        # Ensure the score is within a reasonable range\n",
        "        similarity_score = max(-1.0, min(1.0, similarity_score))\n",
        "\n",
        "        similarities.append((name, similarity_score))\n",
        "\n",
        "    # Sort similarities in descending order\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def process_speaker_recognition(input_file, reference_folder):\n",
        "    \"\"\"\n",
        "    Perform comprehensive speaker recognition\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to input voice file\n",
        "        reference_folder (str): Path to folder with reference voice files\n",
        "\n",
        "    Returns:\n",
        "        list: Top matches with similarity scores\n",
        "    \"\"\"\n",
        "    # Preprocess input voice\n",
        "    input_audio = load_and_preprocess_audio(input_file)\n",
        "\n",
        "    if input_audio is None:\n",
        "        return [(\"Error\", \"Could not process input voice file\")]\n",
        "\n",
        "    # Extract embedding for input voice\n",
        "    input_embedding = extract_voice_embedding(input_audio)\n",
        "\n",
        "    if input_embedding is None:\n",
        "        return [(\"Error\", \"Could not generate input voice embedding\")]\n",
        "\n",
        "    # Print some stats about the input embedding\n",
        "    print(f\"Input embedding shape: {input_embedding.shape}\")\n",
        "    print(f\"Input embedding mean: {np.mean(input_embedding)}\")\n",
        "    print(f\"Input embedding std: {np.std(input_embedding)}\")\n",
        "\n",
        "    # Extract embeddings for all reference voices\n",
        "    reference_embeddings = {}\n",
        "    for filename in os.listdir(reference_folder):\n",
        "        # Support multiple audio formats\n",
        "        if filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):\n",
        "            filepath = os.path.join(reference_folder, filename)\n",
        "\n",
        "            # Preprocess reference audio\n",
        "            ref_audio = load_and_preprocess_audio(filepath)\n",
        "\n",
        "            if ref_audio is not None:\n",
        "                # Extract embedding\n",
        "                embedding = extract_voice_embedding(ref_audio)\n",
        "\n",
        "                if embedding is not None:\n",
        "                    # Use filename (without extension) as the speaker name\n",
        "                    speaker_name = os.path.splitext(filename)[0]\n",
        "                    reference_embeddings[speaker_name] = embedding\n",
        "\n",
        "    # Before running comparisons, print some stats\n",
        "    if len(reference_embeddings) > 0:\n",
        "        print(f\"Found {len(reference_embeddings)} reference embeddings\")\n",
        "\n",
        "        # Check if all embeddings are identical\n",
        "        first_embedding = next(iter(reference_embeddings.values()))\n",
        "        all_identical = all(np.array_equal(embedding, first_embedding)\n",
        "                           for embedding in reference_embeddings.values())\n",
        "        if all_identical:\n",
        "            print(\"WARNING: All reference embeddings are identical!\")\n",
        "    else:\n",
        "        print(\"No reference embeddings found!\")\n",
        "\n",
        "    # Compare embeddings and get top matches\n",
        "    top_matches = compare_voices(input_embedding, reference_embeddings)\n",
        "\n",
        "    return top_matches\n",
        "\n",
        "# Unzip the folder\n",
        "def unzip_folder(zip_path, extract_to='.'):\n",
        "    \"\"\"\n",
        "￼\n",
        "OK\n",
        "\n",
        "    Unzip a folder\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): Path to zip file\n",
        "        extract_to (str): Destination folder\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage\n",
        "# First, unzip the folder\n",
        "unzip_folder('present_maam.zip')\n",
        "\n",
        "# Then run speaker recognition\n",
        "input_voice_file = 'rahultest5.m4a'  # Replace with your input voice file\n",
        "reference_voices_folder = 'present_maam'  # Folder extracted from zip\n",
        "\n",
        "# Perform speaker recognition\n",
        "results = process_speaker_recognition(input_voice_file, reference_voices_folder)\n",
        "\n",
        "# Print results\n",
        "print(\"Top 5 Matches:\")\n",
        "for name, score in results:\n",
        "    if isinstance(score, float):  # Check if score is a float before formatting\n",
        "        print(f\"Speaker: {name}, Similarity Score: {score:.4f}\")\n",
        "    else:\n",
        "        print(f\"Speaker: {name}, Error: {score}\")  # Print the error message"
      ],
      "metadata": {
        "id": "M6f5Ecpj4ILX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e341eb5-5b5d-4334-b448-581723e1b522",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input embedding shape: (52,)\n",
            "Input embedding mean: 5.07429958834272\n",
            "Input embedding std: 44.485705163779315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-12-12494d336d4a>:23: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 42 reference embeddings\n",
            "Top 5 Matches:\n",
            "Speaker: RM_M_2, Similarity Score: 0.6794\n",
            "Speaker: RS_m_1, Similarity Score: 0.6736\n",
            "Speaker: RS_m_2, Similarity Score: 0.6707\n",
            "Speaker: ns_m_14, Similarity Score: 0.6706\n",
            "Speaker: RM_M_4, Similarity Score: 0.6689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MFCC's + i-vectors"
      ],
      "metadata": {
        "id": "p4rDAvxrARYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import torch\n",
        "import torchaudio\n",
        "from scipy.spatial.distance import cosine\n",
        "import zipfile\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn import mixture\n",
        "\n",
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    \"\"\"\n",
        "    Load and preprocess audio file with noise reduction and normalization\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to audio file\n",
        "        target_sr (int): Target sampling rate\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Preprocessed audio signal\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load audio file with librosa (supports multiple formats)\n",
        "        audio, orig_sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "        # Resample if needed\n",
        "        if orig_sr != target_sr:\n",
        "            audio = librosa.resample(audio, orig_sr=orig_sr, target_sr=target_sr)\n",
        "\n",
        "        # Noise reduction using spectral gating\n",
        "        def noise_reduce(y):\n",
        "            # Compute the spectrogram\n",
        "            stft = librosa.stft(y)\n",
        "\n",
        "            # Estimate noise\n",
        "            noise_thresh = np.median(np.abs(stft), axis=1)\n",
        "\n",
        "            # Create a mask to reduce noise\n",
        "            mask = np.abs(stft) > noise_thresh[:, np.newaxis]\n",
        "\n",
        "            # Apply mask\n",
        "            cleaned_stft = stft * mask\n",
        "\n",
        "            # Convert back to time domain\n",
        "            return librosa.istft(cleaned_stft)\n",
        "\n",
        "        # Apply noise reduction\n",
        "        audio = noise_reduce(audio)\n",
        "\n",
        "        # Normalize audio (RMS)\n",
        "        audio = audio / np.sqrt(np.mean(audio**2))\n",
        "\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_mfcc(audio, sr=16000, n_mfcc=20):\n",
        "    \"\"\"\n",
        "    Extract MFCC features\n",
        "\n",
        "    Args:\n",
        "        audio (numpy.ndarray): Audio signal\n",
        "        sr (int): Sampling rate\n",
        "        n_mfcc (int): Number of MFCC coefficients to extract\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: MFCC features\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Extract MFCC features\n",
        "        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc,\n",
        "                                     n_fft=512, hop_length=160)  # 32ms windows with 10ms hop\n",
        "\n",
        "        # Add delta and delta-delta features (velocity and acceleration)\n",
        "        delta_mfccs = librosa.feature.delta(mfccs)\n",
        "        delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
        "\n",
        "        # Stack all features\n",
        "        features = np.vstack([mfccs, delta_mfccs, delta2_mfccs])\n",
        "\n",
        "        return features\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting MFCC: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_ivector(mfcc_features, ubm_model, tv_matrix, num_components=64, tv_dim=100):\n",
        "    \"\"\"\n",
        "    Extract i-vector from MFCC features using a Universal Background Model (UBM)\n",
        "    and Total Variability (TV) matrix\n",
        "\n",
        "    Args:\n",
        "        mfcc_features (numpy.ndarray): MFCC features\n",
        "        ubm_model: GMM-UBM model\n",
        "        tv_matrix (numpy.ndarray): Total Variability matrix\n",
        "        num_components (int): Number of Gaussian components in UBM\n",
        "        tv_dim (int): Dimension of i-vector\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: i-vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # If we don't have a pre-trained UBM, create a simple one\n",
        "        if ubm_model is None:\n",
        "            # Create a simulated UBM (in real applications, this would be pre-trained)\n",
        "            ubm_model = mixture.GaussianMixture(n_components=num_components,\n",
        "                                               covariance_type='diag')\n",
        "            # Transpose to get features in rows for scikit-learn\n",
        "            ubm_model.fit(mfcc_features.T)\n",
        "\n",
        "        # Get frame posteriors for each Gaussian component\n",
        "        posteriors = ubm_model.predict_proba(mfcc_features.T)\n",
        "\n",
        "        # Calculate first-order statistics\n",
        "        # Zero-order statistics\n",
        "        N = np.sum(posteriors, axis=0)\n",
        "\n",
        "        # First-order statistics\n",
        "        F = np.zeros((num_components, mfcc_features.shape[0]))\n",
        "        for c in range(num_components):\n",
        "            F[c] = np.sum(posteriors[:, c:c+1] * mfcc_features.T, axis=0)\n",
        "\n",
        "        # If we don't have a pre-trained TV matrix, create a simulated one\n",
        "        if tv_matrix is None:\n",
        "            # Create a simulated TV matrix (in real applications, this would be pre-trained)\n",
        "            tv_matrix = np.random.normal(0, 1, (num_components * mfcc_features.shape[0], tv_dim))\n",
        "\n",
        "        # Extract i-vector (simplified computation)\n",
        "        # In a real-world scenario, this would involve solving for the MAP point estimate\n",
        "        # Here, we use a simplified approach for demonstration\n",
        "        ivector = np.dot(tv_matrix.T, F.flatten())\n",
        "\n",
        "        # Length-normalize the i-vector\n",
        "        ivector = ivector / np.linalg.norm(ivector)\n",
        "\n",
        "        return ivector\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting i-vector: {e}\")\n",
        "        return np.random.normal(0, 0.1, tv_dim)  # Return random vector in case of failure\n",
        "\n",
        "def train_ubm_and_tv(audio_files, n_components=64, tv_dim=100):\n",
        "    \"\"\"\n",
        "    Train a UBM model and generate a TV matrix from a set of audio files\n",
        "\n",
        "    Args:\n",
        "        audio_files (list): List of audio file paths\n",
        "        n_components (int): Number of Gaussian components\n",
        "        tv_dim (int): Dimension of i-vector\n",
        "\n",
        "    Returns:\n",
        "        tuple: (UBM model, TV matrix)\n",
        "    \"\"\"\n",
        "    # Accumulate features from all files\n",
        "    all_features = []\n",
        "\n",
        "    for file_path in audio_files:\n",
        "        audio = load_and_preprocess_audio(file_path)\n",
        "        if audio is not None:\n",
        "            mfcc_features = extract_mfcc(audio)\n",
        "            if mfcc_features is not None:\n",
        "                all_features.append(mfcc_features.T)  # Transpose for scikit-learn\n",
        "\n",
        "    if not all_features:\n",
        "        print(\"No valid features found for UBM training\")\n",
        "        return None, None\n",
        "\n",
        "    # Concatenate all features\n",
        "    combined_features = np.vstack(all_features)\n",
        "\n",
        "    # Train UBM\n",
        "    print(f\"Training UBM with {combined_features.shape[0]} frames...\")\n",
        "    ubm = mixture.GaussianMixture(n_components=n_components, covariance_type='diag')\n",
        "    ubm.fit(combined_features)\n",
        "\n",
        "    # Generate a simplified TV matrix\n",
        "    # In real applications, this would be learned from data\n",
        "    feature_dim = all_features[0].shape[1]\n",
        "    tv_matrix = np.random.normal(0, 1, (n_components * feature_dim, tv_dim))\n",
        "\n",
        "    return ubm, tv_matrix\n",
        "\n",
        "def extract_voice_embedding(audio, ubm_model=None, tv_matrix=None):\n",
        "    \"\"\"\n",
        "    Extract voice embedding from preprocessed audio using MFCC and i-vector features\n",
        "\n",
        "    Args:\n",
        "        audio (numpy.ndarray): Preprocessed audio signal\n",
        "        ubm_model: GMM-UBM model\n",
        "        tv_matrix: Total Variability matrix\n",
        "\n",
        "    Returns:\n",
        "        numpy.ndarray: Voice embedding vector\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Ensure audio is the right length\n",
        "        target_length = 3 * 16000  # 3 seconds at 16kHz\n",
        "        if len(audio) > target_length:\n",
        "            audio = audio[:target_length]\n",
        "        elif len(audio) < target_length:\n",
        "            audio = np.pad(audio, (0, target_length - len(audio)), mode='constant')\n",
        "\n",
        "        # Extract MFCC features\n",
        "        mfcc_features = extract_mfcc(audio, sr=16000, n_mfcc=20)\n",
        "\n",
        "        if mfcc_features is None:\n",
        "            return None\n",
        "\n",
        "        # Compute MFCC statistics\n",
        "        mfcc_mean = np.mean(mfcc_features, axis=1)\n",
        "        mfcc_std = np.std(mfcc_features, axis=1)\n",
        "\n",
        "        # Extract i-vector\n",
        "        ivector = extract_ivector(mfcc_features, ubm_model, tv_matrix)\n",
        "\n",
        "        # Combine MFCC statistics and i-vector into a single embedding\n",
        "        embedding = np.concatenate([mfcc_mean, mfcc_std, ivector])\n",
        "\n",
        "        # Add small random noise to prevent perfect matches\n",
        "        np.random.seed(42)  # For reproducibility\n",
        "        embedding += np.random.normal(0, 1e-5, embedding.shape)\n",
        "\n",
        "        # Normalize the embedding\n",
        "        embedding = embedding / np.linalg.norm(embedding)\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def compare_voices(input_embedding, reference_embeddings, top_n=5):\n",
        "    \"\"\"\n",
        "    Compare input voice embedding with reference embeddings\n",
        "\n",
        "    Args:\n",
        "        input_embedding (numpy.ndarray): Embedding of input voice\n",
        "        reference_embeddings (dict): Dictionary of reference voice embeddings\n",
        "        top_n (int): Number of top matches to return\n",
        "\n",
        "    Returns:\n",
        "        list: Top N matches with similarity scores\n",
        "    \"\"\"\n",
        "    similarities = []\n",
        "\n",
        "    # Debug: check if input embedding has valid values\n",
        "    if np.all(np.isnan(input_embedding)) or np.all(input_embedding == 0):\n",
        "        print(\"Warning: Input embedding contains all NaN or zero values\")\n",
        "        return [(\"Error\", 0.0)]\n",
        "\n",
        "    for name, ref_embedding in reference_embeddings.items():\n",
        "        # Skip invalid embeddings\n",
        "        if np.all(np.isnan(ref_embedding)) or np.all(ref_embedding == 0):\n",
        "            print(f\"Warning: Reference embedding for {name} contains all NaN or zero values\")\n",
        "            continue\n",
        "\n",
        "        # 1. Cosine similarity (bounded between -1 and 1)\n",
        "        cosine_sim = 1 - cosine(input_embedding, ref_embedding)\n",
        "\n",
        "        # 2. Modified Euclidean similarity calculation\n",
        "        euclidean_dist = np.linalg.norm(input_embedding - ref_embedding)\n",
        "        # Use a more stable approach for Euclidean similarity\n",
        "        euclidean_sim = 1 / (1 + euclidean_dist)  # This will be between 0 and 1\n",
        "\n",
        "        # Combined score (weighted average)\n",
        "        similarity_score = 0.7 * cosine_sim + 0.3 * euclidean_sim\n",
        "\n",
        "        # Ensure the score is within a reasonable range\n",
        "        similarity_score = max(-1.0, min(1.0, similarity_score))\n",
        "\n",
        "        similarities.append((name, similarity_score))\n",
        "\n",
        "    # Sort similarities in descending order\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def process_speaker_recognition(input_file, reference_folder):\n",
        "    \"\"\"\n",
        "    Perform comprehensive speaker recognition\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to input voice file\n",
        "        reference_folder (str): Path to folder with reference voice files\n",
        "\n",
        "    Returns:\n",
        "        list: Top matches with similarity scores\n",
        "    \"\"\"\n",
        "    # Get all audio files for UBM training\n",
        "    all_audio_files = []\n",
        "    for filename in os.listdir(reference_folder):\n",
        "        if filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):\n",
        "            filepath = os.path.join(reference_folder, filename)\n",
        "            all_audio_files.append(filepath)\n",
        "\n",
        "    # Add the input file to training data\n",
        "    all_audio_files.append(input_file)\n",
        "\n",
        "    # Train UBM and generate TV matrix\n",
        "    ubm_model, tv_matrix = train_ubm_and_tv(all_audio_files)\n",
        "\n",
        "    # Preprocess input voice\n",
        "    input_audio = load_and_preprocess_audio(input_file)\n",
        "\n",
        "    if input_audio is None:\n",
        "        return [(\"Error\", \"Could not process input voice file\")]\n",
        "\n",
        "    # Extract embedding for input voice\n",
        "    input_embedding = extract_voice_embedding(input_audio, ubm_model, tv_matrix)\n",
        "\n",
        "    if input_embedding is None:\n",
        "        return [(\"Error\", \"Could not generate input voice embedding\")]\n",
        "\n",
        "    # Print some stats about the input embedding\n",
        "    print(f\"Input embedding shape: {input_embedding.shape}\")\n",
        "    print(f\"Input embedding mean: {np.mean(input_embedding)}\")\n",
        "    print(f\"Input embedding std: {np.std(input_embedding)}\")\n",
        "\n",
        "    # Extract embeddings for all reference voices\n",
        "    reference_embeddings = {}\n",
        "    for filename in os.listdir(reference_folder):\n",
        "        # Support multiple audio formats\n",
        "        if filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):\n",
        "            filepath = os.path.join(reference_folder, filename)\n",
        "\n",
        "            # Preprocess reference audio\n",
        "            ref_audio = load_and_preprocess_audio(filepath)\n",
        "\n",
        "            if ref_audio is not None:\n",
        "                # Extract embedding\n",
        "                embedding = extract_voice_embedding(ref_audio, ubm_model, tv_matrix)\n",
        "\n",
        "                if embedding is not None:\n",
        "                    # Use filename (without extension) as the speaker name\n",
        "                    speaker_name = os.path.splitext(filename)[0]\n",
        "                    reference_embeddings[speaker_name] = embedding\n",
        "\n",
        "    # Before running comparisons, print some stats\n",
        "    if len(reference_embeddings) > 0:\n",
        "        print(f\"Found {len(reference_embeddings)} reference embeddings\")\n",
        "\n",
        "        # Check if all embeddings are identical\n",
        "        first_embedding = next(iter(reference_embeddings.values()))\n",
        "        all_identical = all(np.array_equal(embedding, first_embedding)\n",
        "                           for embedding in reference_embeddings.values())\n",
        "        if all_identical:\n",
        "            print(\"WARNING: All reference embeddings are identical!\")\n",
        "    else:\n",
        "        print(\"No reference embeddings found!\")\n",
        "\n",
        "    # Compare embeddings and get top matches\n",
        "    top_matches = compare_voices(input_embedding, reference_embeddings)\n",
        "\n",
        "    return top_matches\n",
        "\n",
        "# Unzip the folder\n",
        "def unzip_folder(zip_path, extract_to='.'):\n",
        "    \"\"\"\n",
        "    Unzip a folder\n",
        "\n",
        "    Args:\n",
        "        zip_path (str): Path to zip file\n",
        "        extract_to (str): Destination folder\n",
        "    \"\"\"\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # First, unzip the folder\n",
        "    unzip_folder('present_maam.zip')\n",
        "\n",
        "    # Then run speaker recognition\n",
        "    input_voice_file = 'rahultest5.m4a'  # Replace with your input voice file\n",
        "    reference_voices_folder = 'present_maam'  # Folder extracted from zip\n",
        "\n",
        "    # Perform speaker recognition\n",
        "    results = process_speaker_recognition(input_voice_file, reference_voices_folder)\n",
        "\n",
        "    # Print results\n",
        "    print(\"\\nTop 5 Matches:\")\n",
        "    for name, score in results:\n",
        "        print(f\"Speaker: {name}, Similarity Score: {score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpK4WNEcATSp",
        "outputId": "286b187d-d968-44be-f997-b95a56af3f76",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training UBM with 7910 frames...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input embedding shape: (220,)\n",
            "Input embedding mean: 0.002736559266223857\n",
            "Input embedding std: 0.06736442524683922\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
            "<ipython-input-17-2cb73215015c>:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, orig_sr = librosa.load(file_path, sr=None)\n",
            "/usr/local/lib/python3.11/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 42 reference embeddings\n",
            "\n",
            "Top 5 Matches:\n",
            "Speaker: RM_M_2, Similarity Score: 0.9436\n",
            "Speaker: RS_m_2, Similarity Score: 0.9435\n",
            "Speaker: RM_M_7, Similarity Score: 0.9415\n",
            "Speaker: RS_m_1, Similarity Score: 0.9407\n",
            "Speaker: RS_m_4, Similarity Score: 0.9375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using the speechbrain model (optimized)"
      ],
      "metadata": {
        "id": "75mPZ0h8KsH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import logging\n",
        "import numpy as np\n",
        "import torchaudio\n",
        "import torch\n",
        "import zipfile\n",
        "from speechbrain.pretrained import SpeakerRecognition\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "# Load SpeechBrain model once\n",
        "model = SpeakerRecognition.from_hparams(\n",
        "    source=\"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    savedir=\"pretrained_models/spkrec-ecapa-voxceleb\"\n",
        ")\n",
        "\n",
        "def load_and_preprocess_audio(file_path, target_sr=16000):\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        # Load audio with torchaudio\n",
        "        audio, orig_sr = torchaudio.load(file_path)\n",
        "\n",
        "        # Resample if needed\n",
        "        if orig_sr != target_sr:\n",
        "            transform = torchaudio.transforms.Resample(orig_sr, target_sr)\n",
        "            audio = transform(audio)\n",
        "\n",
        "        # Convert to mono\n",
        "        if audio.shape[0] > 1:\n",
        "            audio = torch.mean(audio, dim=0, keepdim=True)\n",
        "\n",
        "        # Convert tensor to NumPy array\n",
        "        audio = audio.squeeze().numpy()\n",
        "\n",
        "        # Normalize audio (RMS)\n",
        "        audio = audio / np.sqrt(np.mean(audio**2))\n",
        "\n",
        "        logging.info(f\"Processed {file_path} in {time.time() - start_time:.2f}s\")\n",
        "        return audio\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error processing {file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_voice_embedding(audio):\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        # Convert numpy array to torch tensor\n",
        "        audio_tensor = torch.tensor(audio).float().unsqueeze(0)\n",
        "\n",
        "        # Ensure tensor length (3 seconds at 16kHz)\n",
        "        target_length = 3 * 16000\n",
        "        if audio_tensor.shape[1] > target_length:\n",
        "            audio_tensor = audio_tensor[:, :target_length]\n",
        "        elif audio_tensor.shape[1] < target_length:\n",
        "            padding = torch.zeros(1, target_length - audio_tensor.shape[1])\n",
        "            audio_tensor = torch.cat([audio_tensor, padding], dim=1)\n",
        "\n",
        "        # Extract embedding\n",
        "        embedding = model.encode_batch(audio_tensor).squeeze().numpy()\n",
        "\n",
        "        logging.info(f\"Extracted embedding in {time.time() - start_time:.2f}s\")\n",
        "        return embedding\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error generating embedding: {e}\")\n",
        "        return None\n",
        "\n",
        "def compare_voices(input_embedding, reference_embeddings, top_n=5):\n",
        "    start_time = time.time()\n",
        "    similarities = []\n",
        "\n",
        "    for name, ref_embedding in reference_embeddings.items():\n",
        "        # Compute cosine similarity using NumPy\n",
        "        similarity_score = np.dot(input_embedding, ref_embedding) / (np.linalg.norm(input_embedding) * np.linalg.norm(ref_embedding))\n",
        "        similarities.append((name, similarity_score))\n",
        "\n",
        "    # Sort by similarity\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    logging.info(f\"Compared voices in {time.time() - start_time:.2f}s\")\n",
        "    return similarities[:top_n]\n",
        "\n",
        "def process_speaker_recognition(input_file, reference_folder):\n",
        "    input_audio = load_and_preprocess_audio(input_file)\n",
        "    if input_audio is None:\n",
        "        return [(\"Error\", \"Could not process input voice file\")]\n",
        "\n",
        "    input_embedding = extract_voice_embedding(input_audio)\n",
        "    if input_embedding is None:\n",
        "        return [(\"Error\", \"Could not generate input voice embedding\")]\n",
        "\n",
        "    reference_embeddings = {}\n",
        "    for filename in os.listdir(reference_folder):\n",
        "        if filename.lower().endswith(('.wav', '.mp3', '.flac', '.ogg', '.m4a')):\n",
        "            filepath = os.path.join(reference_folder, filename)\n",
        "            ref_audio = load_and_preprocess_audio(filepath)\n",
        "            if ref_audio is not None:\n",
        "                embedding = extract_voice_embedding(ref_audio)\n",
        "                if embedding is not None:\n",
        "                    reference_embeddings[os.path.splitext(filename)[0]] = embedding\n",
        "\n",
        "    return compare_voices(input_embedding, reference_embeddings)\n",
        "\n",
        "def unzip_folder(zip_path, extract_to='.'):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "\n",
        "# Example usage\n",
        "unzip_folder('present_maam.zip')\n",
        "input_voice_file = 'rahultest5.m4a'\n",
        "reference_voices_folder = 'present_maam'\n",
        "results = process_speaker_recognition(input_voice_file, reference_voices_folder)\n",
        "print(\"Top 5 Matches:\")\n",
        "for name, score in results:\n",
        "    print(f\"Speaker: {name}, Similarity Score: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnY7_qRbKv_r",
        "outputId": "f6790571-6f97-4eb0-99a8-150ab909a1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Matches:\n",
            "Speaker: RS_m_5, Similarity Score: 0.5395\n",
            "Speaker: RM_M_4, Similarity Score: 0.4146\n",
            "Speaker: RM_M_9, Similarity Score: 0.3657\n",
            "Speaker: RM_M_7, Similarity Score: 0.3604\n",
            "Speaker: RS_m_1, Similarity Score: 0.3444\n"
          ]
        }
      ]
    }
  ]
}